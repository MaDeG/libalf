\chapter{Filters \& Normalizers}
A knowledgebase can be associated with \textbf{filters} which can exploit domain specific properties and by that actively reduce the number of queries to the teacher during the learning phase. Such filters can be composed by logical connectors (and, or, not). \\
In contrast, \textbf{Normalizers} recognize equivalent words in a domain-specific sense to reduce the amount of knowledge that has to be stored. \\
Both components can be serialized and deserialized.

\section{Filters}

A knowledgebase can be associated with more than one filter through the logical connectors. A filter essentially works on the word and tries to resolve its classification. Thus, it reduces the number of queries that are asked to the teacher. You may also connect the filters with more than one logical connectors and, or and not.
\paragraph{A simple example}
Lets assume that you have associated two filters with learning algorithm. You wish that the classification of word is 1 (accepted) if only both the filters give positive results and is 0 (rejected) if even one of the filters give a negative result. \libalf lets you connect these filters with logical connector ``and'' so that the above operation is precisely performed. \\
In the following material, we discuss the methods associated with Filters are implemented and how to work with it.

\subsection{Class - filter}
It is the main class that defines the types of filter.

\subsection*{Attributes - filter types}
An \emph{enum} type variable \texttt{type} is used to define the filter type.
\begin{itemize}
 \item \textbf{FILTER\_NONE = 0} ; No filter associated
 \item \textbf{FILTER\_AND = 1} ; Filter type \emph{and}
 \item \textbf{FILTER\_OR = 2} ; Filter type \emph{or}
 \item \textbf{FILTER\_NOT = 3} ; Filter type \emph{not}
 \item \textbf{FILTER\_ALL\_EQUAL = 4} ; Filter type for equal words
 \item \textbf{FILTER\_REVERSE = 100} ; Filter type handling reverse of a word.
 \item \textbf{FILTER\_IDENTITY = 200} ; Identity filter **
\end{itemize}

\subsection{Class - filter\_subfilter\_array}
The subfilter is an array of filters that is used to associate more than one filter to the knowledgebase. The class inherits the filter class.
\subsection*{Attributes}
\begin{itemize}
 \item \textbf{list$<$filter$<$answer$>$*$>$ subfilter\_array} \\
	A list of all the subfilters associated with the knowledgebase.
\end{itemize}
\subsection*{Methods}
\begin{itemize}
 \item \textbf{virtual void free\_all\_subfilter()} \\
	The method to erase all subfilters.
 \item \textbf{virtual void add(filter$<$answer$>$ *f)} \\
	Method to add a filter into the array.
 \item \textbf{virtual void remove(filter$<$answer$>$ *f)} \\
	Method to remove a filter from the array.
\end{itemize}

\subsection{Important Methods of all Filters}

All the filters (including the logical connectors) are associated with the following important methods that execute its feature.

\begin{enumerate}
 
\item \textbf{filter::void free\_all\_subfilter()} \\
	Method to erase all the subfilters (logical connectors) associated with the knowledgebase.
 \item \textbf{filter::virtual enum type get\_type()} \\
	The method returns the type of filter. 
 \item \textbf{filter::virtual bool evaluate(knowledgebase$<$answer$>$ \& base, list$<$int$>$ \& word, answer \& result)} \\
	The main method to evaluate the word with the associated filter. It returns \true if the word was evaluated successfully and the answer is stored in the parameter \texttt{result}. It returns \false otherwise.
\end{enumerate}


\subsection{Types of Filters}
\begin{enumerate}
 
\item \textbf{filter\_and} \\
It is the logical connector \texttt{and} that can be associated with any two filters. The \texttt{evaluate} method returns \true only if the answer of the word can be determined by both the associated filters and the answer obtained is the same.

\item \textbf{filter\_or}  \\
It is the logical connector \texttt{or} that can be associated with any two filters. It returns \true if the word if at least one of the filters provide an answer for the word.

\item \textbf{filter\_not} \\
It is the logical connector \texttt{not} that can be associated with a filter. It returns \true if the word was answered by the filter and sets the \texttt{result} to the \texttt{not} of the derived answer.

\item \textbf{filter\_all\_equal} \\
Filter to check if the result is the same in all filters. Returns \true if the subfilter array is non-empty, and if all filters can evaluate a word and produce the same answer. 

\item \textbf{filter\_reverse} \\
The filter reverses the word and sends to all subfilters. Returns \true if the reversed word can be evaluated by the subfilters and the answer is stored to the \texttt{result}.

\item \textbf{filter\_identity} \\
This is a filter that tries to identify if the answer to the word is already available in the knowledgebase. It returns \true if it exists and is answered already (after setting the answer to \texttt{result}), \false otherwise.

\end{enumerate}

\section{Normalizers}

As mentioned before, Normalizers are means to reduce memory consumption during the learning phase. A normalizer defines a domain-specific equivalence relation (...) over all words and only stores data for one representative of each equivlance class. This means that the data for equivalent queries is only queried and stored once. Apart from reducing the memory consumption, the number of queries are also reduced. By subtyping the respective interface, a user can easily define her own domain-specific optimizations. Normalizers are extensively used by Angluin Algorithm.

\subsection{Working Overview}

Normalizers are based on the concept of Message Sequence charts (MSC). An MSC consists of a set of processes (or nodes) P, set of messages M, a set E of events which is partitioned into a set S of \emph{send} events and a set R of \emph{receive} events
In the normalizer, the send and receive events are organized as odd and even pairs respectively. Odd represents the send event of the sending process and even represents the receive event of the receiving process. The processes pass the symbols of the word as the messages and the normalizer tries to identify if the word belongs to the MSC's language. If yes, it returns the normalized word available in the knowledgebase. In this way, the need to store another word is eliminated. \\
Normalizer also supports the serialize and deserialize features. 

\subsection{Methods}
The methods governing this component is described below.
\subsubsection*{User Perspective}
From the user perspective, the two important methods that perform the normalization are given below. You can simply associate a normalizer with your Angluin learning algorithm.
\begin{itemize}
 \item \textbf{list$<$int$>$ normalizer\_msc::prefix\_normal\_form(list$<$int$>$ \& w, bool \& bottom)}
	This is the method that normalizes the given input. The parameter \emph{w} is the word. The method creates the MSC and then attempts to normalize the word. If successful, it returns the normalized word. Otherwise \emph{bottom} is set to true and it returns the BOTTOM\_CHAR. 
 \item \textbf{list$<$int$>$ normalize\_msc::suffix\_normal\_form(list$<$int$>$ \& w, bool \& bottom)}
	This method performs the same operation as the previous method except that a reversed MSC is created.
\end{itemize}


\subsubsection*{Developer Perspective}
The MSC is stored in the form of a graph. The important attributes are as follows.
\begin{enumerate}
 \item \textbf{vector$<$int$>$ total\_order} - Denotes the total order. A total order is nothing but the temporal order of the messages that are available for the events in the buffer.
 \item \textbf{vector$<$int$>$ process\_match} - A relation that matches the events to a process.
 \item \textbf{vector$<$int$>$ buffer\_match} - A relation matching event to a buffer. The messages are queued in send and receive buffers.
 \item \textbf{int max\_buffer\_length} - The maximum number of messages in a buffer.
 \item \textbf{list$<$msc::msc\_node*$>$ graph} - Variable for storing the graph
 \item \textbf{queue$<$int$>$ * buffers} - The buffers.
 \item \textbf{unsigned int buffercount} - The count of number of buffers used.
 \item \textbf{unsigned int label\_bound} - The label bound is essentially the alphabet size known by the normalizer. A message must be in [0, label\_bound).
\end{enumerate}

The important methods are given below.
\begin{enumerate}
 \item \textbf{void graph\_add\_node(int id, int label, bool pnf)} \\
	The method is used to add node to the graph. This method is used by the prefix and suffix normal form methods. There are two things to be noted here. First, the process connection for prefix\_normal\_form (PNF), a connection is made to the node from other youngest node with same process that is not connected. For suffix\_normal\_form (SNF), a connection is made from node to other youngest node with same process that is not connected. The connection between the messages is again ruled by PNF or SNF. For PNF, a receiving event is connected to oldest corresponding send-event that is not connected and for SNF, a sending event is connected from oldest corresponding send-event that is not connected.
 \item \textbf{void normalizer\_msc::clear\_buffers(list$<$int$>$ word)} \\
        Clears all buffers that this word has touched.
 \item \textbf{bool normalizer\_msc::check\_buffer(int label, bool pnf)} \\
	The method checks if the message (label) can be put into its buffer or taken from its buffer. If yes, returns \true. On the otherhand, if its buffer is full or another message is at the head of the buffer, it returns \false.
 \item \textbf{int normalizer\_msc::graph\_reduce(bool pnf)} \\
	This is the actual method used by the PNF and SNF methods for normalization.  
 \item \textbf{inline void connect\_buffer(msc\_node * other)} \\
	Method to connect the buffers.
\end{enumerate}
